{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install pyTelegramBotAPI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdWcL4Ge43Mx",
        "outputId": "ff5b20f4-20c7-42cc-8adf-51033198749f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyTelegramBotAPI in /usr/local/lib/python3.10/dist-packages (4.20.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from pyTelegramBotAPI) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->pyTelegramBotAPI) (2024.6.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import telebot\n",
        "import requests\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "from transformers import ViltProcessor, ViltForQuestionAnswering\n",
        "import yfinance as yf\n",
        "from datetime import datetime\n",
        "import google.generativeai as genai\n",
        "\n",
        "\n",
        "\n",
        "# Replace with your Telegram bot token and Hugging Face API key\n",
        "TELEGRAM_TOKEN = \"6822466398:AAEzOBHnMqD7bBl1VBCae-MKmsckWfElmJk\"\n",
        "HUGGING_API_KEY = \"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\"\n",
        "GEMINI_API_KEY = \"AIzaSyDB6JTTmGg-0VhyGfmgzfgCHHl2qnt2OTU\"\n",
        "OPENWEATHER_API_KEY = \"84190506d5bf0843188d4a9531d7117c\"\n",
        "\n",
        "# Initialize the Telegram bot\n",
        "bot = telebot.TeleBot(TELEGRAM_TOKEN)\n",
        "\n",
        "# Initialize the VQA model and processor\n",
        "vqa_processor = ViltProcessor.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
        "vqa_model = ViltForQuestionAnswering.from_pretrained(\"dandelin/vilt-b32-finetuned-vqa\")\n",
        "\n",
        "# Configure Google Gemini API\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Function to call Google Gemini API\n",
        "def call_gemini_api(prompt):\n",
        "    model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text.strip()\n",
        "\n",
        "# Function to generate image based on user prompt using Hugging Face's API\n",
        "def generate_and_show_image(message, prompt):\n",
        "    try:\n",
        "        url = \"https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-xl-base-1.0\"\n",
        "        headers = {\n",
        "            \"Authorization\": f\"Bearer {HUGGING_API_KEY}\",\n",
        "            \"Content-Type\": \"application/json\"\n",
        "        }\n",
        "        payload = {\n",
        "            \"inputs\": prompt\n",
        "        }\n",
        "        response = requests.post(url, headers=headers, json=payload)\n",
        "\n",
        "        if response.status_code == 200:\n",
        "            img_data = response.content\n",
        "            img = Image.open(BytesIO(img_data))\n",
        "\n",
        "            # Send the image to the user\n",
        "            img_stream = BytesIO()\n",
        "            img.save(img_stream, format='PNG')\n",
        "            img_stream.seek(0)\n",
        "            bot.send_photo(message.chat.id, img_stream)\n",
        "        else:\n",
        "            bot.reply_to(message, f\"Error generating image: {response.status_code} - {response.text}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        bot.reply_to(message, f\"An error occurred: {e}\")\n",
        "\n",
        "# Helper functions\n",
        "def get_weather(city):\n",
        "    url = f\"http://api.openweathermap.org/data/2.5/weather?q={city}&appid={OPENWEATHER_API_KEY}&units=metric\"\n",
        "    response = requests.get(url).json()\n",
        "    if response.get(\"cod\") != 200:\n",
        "        return \"City not found.\"\n",
        "    weather = response[\"weather\"][0][\"description\"]\n",
        "    temp = response[\"main\"][\"temp\"]\n",
        "    return f\"Weather in {city}: {weather}, {temp}Â°C\"\n",
        "\n",
        "def answer_question(image, question):\n",
        "    encoding = vqa_processor(image, question, return_tensors=\"pt\")\n",
        "    outputs = vqa_model(**encoding)\n",
        "    logits = outputs.logits\n",
        "    idx = logits.argmax(-1).item()\n",
        "    return vqa_model.config.id2label[idx]\n",
        "\n",
        "def predict_stock(stock_ticker):\n",
        "    stock = yf.Ticker(stock_ticker)\n",
        "    hist = stock.history(period=\"5d\")\n",
        "    return f\"Stock price for {stock_ticker}:\\n{hist[['Close']].to_string()}\"\n",
        "\n",
        "# Predefined responses for the chatbot\n",
        "chatbot_responses = {\n",
        "    \"How are you?\": \"I'm good, thank you!\",\n",
        "    \"What are you doing?\": \"Just chatting with you.\",\n",
        "    \"Who created you?\": \"I was created by an awesome developer.\",\n",
        "    \"Tell me a joke.\": \"Why don't scientists trust atoms? Because they make up everything!\",\n",
        "    \"Goodbye\": \"Goodbye! Have a nice day.\"\n",
        "}\n",
        "\n",
        "# Bot handlers\n",
        "@bot.message_handler(commands=['start', 'help'])\n",
        "def send_welcome(message):\n",
        "    markup = telebot.types.ReplyKeyboardMarkup(row_width=2, resize_keyboard=True)\n",
        "    weather_btn = telebot.types.KeyboardButton('Current Weather')\n",
        "    chatbot_btn = telebot.types.KeyboardButton('Chatbot')\n",
        "    markup.add(weather_btn,chatbot_btn)\n",
        "    bot.send_message(message.chat.id, \"Choose an option:\", reply_markup=markup)\n",
        "\n",
        "@bot.message_handler(func=lambda message: message.text == 'Current Weather')\n",
        "def weather_option(message):\n",
        "    msg = bot.send_message(message.chat.id, \"Enter the city name:\")\n",
        "    bot.register_next_step_handler(msg, send_weather)\n",
        "\n",
        "def send_weather(message):\n",
        "    city = message.text\n",
        "    weather_info = get_weather(city)\n",
        "    bot.send_message(message.chat.id, weather_info)\n",
        "\n",
        "@bot.message_handler(func=lambda message: message.text == 'Chatbot')\n",
        "def chatbot_option(message):\n",
        "    msg = bot.send_message(message.chat.id, \"Ask me anything:\")\n",
        "    bot.register_next_step_handler(msg, chatbot_response)\n",
        "\n",
        "def chatbot_response(message):\n",
        "    session_id = message.chat.id\n",
        "    user_input = message.text\n",
        "    response = call_gemini_api(user_input)  # Using Gemini API for chatbot response\n",
        "    bot.send_message(message.chat.id, response)\n",
        "\n",
        "# Start the bot\n",
        "bot.polling()"
      ],
      "metadata": {
        "id": "QQebnTlI4Pks"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}